services:
  llm:
    image: "docker.io/ollama/ollama"
    volumes:
      - ollama_data:/root/.ollama
    entrypoint: ["/usr/bin/bash", "-c", "/bin/ollama serve & sleep 5; ollama pull qwen2:0.5b; wait"]

  app:
    build: ./app
    image: "docker.io/0xr3x/verifier-agent:latest"
    platform: linux/amd64
    ports:
      - "4021:4021"
    volumes:
      - /run/rofl-appd.sock:/run/rofl-appd.sock
    environment:
      - ENDPOINT_URL=${ENDPOINT_URL:-http://localhost:4021/verify}
      - OLLAMA_HOST=http://llm:11434
      - ENVIRONMENT=${ENVIRONMENT:-development}
    depends_on:
      - llm

volumes:
  ollama_data:
