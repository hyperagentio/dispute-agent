services:
  llm:
    image: "docker.io/ollama/ollama"
    volumes:
      - ollama_data:/root/.ollama
    entrypoint: ["/usr/bin/bash", "-c", "/bin/ollama serve & sleep 5; ollama pull qwen2:0.5b; wait"]

  app:
    build: ./app
    image: "docker.io/0xr3x/verifier-agent:latest"
    platform: linux/amd64
    ports:
      - "4021:4021"
    volumes:
      - /run/rofl-appd.sock:/run/rofl-appd.sock
    environment:
      - ENDPOINT_URL=${ENDPOINT_URL:-http://localhost:4021/verify}
      - OLLAMA_HOST=http://llm:11434
      - ENVIRONMENT=${ENVIRONMENT:-development}
      - PRIVATE_KEY=${PRIVATE_KEY}
      - HEDERA_NETWORK=${HEDERA_NETWORK:-testnet}
      - JOBS_MODULE_ADDRESS=${JOBS_MODULE_ADDRESS:-0x7f99ED407aBE6a8da0f88C7282909fE818515416}
      - DEBUG_SIGNING=${DEBUG_SIGNING:-true}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-qwen2:0.5b}
    depends_on:
      - llm

volumes:
  ollama_data:
